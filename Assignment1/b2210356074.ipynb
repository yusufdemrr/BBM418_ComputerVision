{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Initialization and Visualization\n",
    "\n",
    "### Purpose\n",
    "This part of the code initializes the dataset by loading file paths of distorted and ground truth images for different categories. It also visualizes a sample image from each category along with its dimensions.\n",
    "\n",
    "### Steps\n",
    "1. **Define Dataset Path**  \n",
    "   - The dataset path is set to `/Users/demir/Desktop/Assignment1/WarpDoc`, which should be updated as needed.\n",
    "  \n",
    "2. **Load Image Paths**  \n",
    "   - The dataset consists of six categories: `curved`, `fold`, `incomplete`, `perspective`, `random`, and `rotate`.\n",
    "   - Image paths for each category are loaded separately for distorted and ground truth images.\n",
    "   - If the corresponding folder does not exist, a warning message is displayed.\n",
    "\n",
    "3. **Visualizing Sample Images**\n",
    "   - A function `show_sample_images()` is defined to:\n",
    "     - Load and display a distorted and its corresponding ground truth image for each category.\n",
    "     - Convert images from BGR to RGB (since OpenCV loads images in BGR format).\n",
    "     - Extract and display the image dimensions in the plot title.\n",
    "   - The function is called at the end to visualize the images.\n",
    "\n",
    "### Key Libraries Used\n",
    "- `os`: For accessing file paths.\n",
    "- `cv2`: For image reading and processing.\n",
    "- `matplotlib.pyplot`: For visualizing images.\n",
    "\n",
    "### Expected Output\n",
    "- A figure displaying two rows:\n",
    "  - **Top row:** Distorted images from each category.\n",
    "  - **Bottom row:** Corresponding ground truth images.\n",
    "- Titles include category names and image dimensions.\n",
    "\n",
    "This step ensures that the dataset is correctly loaded and provides an initial visual inspection of distortions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset path\n",
    "dataset_path = '/Users/demir/Desktop/Assignment1/WarpDoc'  # Update this with your own file path\n",
    "\n",
    "# Define categories\n",
    "categories = ['curved', 'fold', 'incomplete', 'perspective', 'random', 'rotate']\n",
    "image_paths = {}\n",
    "\n",
    "# Load image file paths for each category (without resizing)\n",
    "for category in categories:\n",
    "    distorted_path = os.path.join(dataset_path, 'distorted', category)\n",
    "    ground_truth_path = os.path.join(dataset_path, 'digital', category)\n",
    "    \n",
    "    if os.path.exists(distorted_path) and os.path.exists(ground_truth_path):\n",
    "        distorted_images = [os.path.join(distorted_path, img) for img in os.listdir(distorted_path)]\n",
    "        ground_truth_images = [os.path.join(ground_truth_path, img) for img in os.listdir(ground_truth_path)]\n",
    "        image_paths[category] = {'distorted': distorted_images, 'ground_truth': ground_truth_images}\n",
    "    else:\n",
    "        print(f\"Folder not found for category: {category}\")\n",
    "\n",
    "# Function to visualize sample images from each category and display their dimensions\n",
    "def show_sample_images(image_paths, categories):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i, category in enumerate(categories):\n",
    "        if category in image_paths and image_paths[category]['distorted']:\n",
    "            # Get the first image path for distorted and ground truth images\n",
    "            distorted_img_path = image_paths[category]['distorted'][0]\n",
    "            ground_truth_img_path = image_paths[category]['ground_truth'][0]\n",
    "            \n",
    "            # Load images using OpenCV and convert BGR to RGB for display\n",
    "            distorted_img = cv2.imread(distorted_img_path, cv2.IMREAD_COLOR)\n",
    "            distorted_img_rgb = cv2.cvtColor(distorted_img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            ground_truth_img = cv2.imread(ground_truth_img_path, cv2.IMREAD_COLOR)\n",
    "            ground_truth_img_rgb = cv2.cvtColor(ground_truth_img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Get image dimensions (width and height)\n",
    "            d_height, d_width = distorted_img.shape[:2]\n",
    "            gt_height, gt_width = ground_truth_img.shape[:2]\n",
    "            \n",
    "            # Plot distorted image in the first row with dimensions in the title\n",
    "            plt.subplot(2, len(categories), i+1)\n",
    "            plt.imshow(distorted_img_rgb)\n",
    "            plt.title(f'Distorted: {category}\\n{d_width}x{d_height}')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Plot ground truth image in the second row with dimensions in the title\n",
    "            plt.subplot(2, len(categories), i+1+len(categories))\n",
    "            plt.imshow(ground_truth_img_rgb)\n",
    "            plt.title(f'Ground Truth: {category}\\n{gt_width}x{gt_height}')\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display sample images along with their dimensions\n",
    "show_sample_images(image_paths, categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Resizing for Dataset Preprocessing\n",
    "\n",
    "To ensure uniform image dimensions, this step resizes images while preserving aspect ratio. If an image's longest side exceeds `max_dim` (1500 pixels), it is scaled down. Otherwise, it remains unchanged. The function `resize_image_if_needed()` handles resizing.\n",
    "\n",
    "Another function, `resize_and_save_images()`, creates a new dataset folder structure (`distorted` and `digital`), replicating the original hierarchy. It resizes images only when necessary and avoids redundant processing. This step standardizes input sizes, improving efficiency in later stages like edge detection and geometric transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image_if_needed(img, max_dim=1500):\n",
    "    \"\"\"\n",
    "    Resize the image if its longest side is greater than max_dim.\n",
    "    Otherwise, return the original image.\n",
    "    \n",
    "    Parameters:\n",
    "        img (numpy.ndarray): The original image in BGR format.\n",
    "        max_dim (int): Maximum size for the longest side of the image.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Resized image if needed, otherwise the original.\n",
    "    \"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    longest_side = max(h, w)\n",
    "    \n",
    "    if longest_side > max_dim:\n",
    "        scale = max_dim / float(longest_side)\n",
    "        new_w = int(w * scale)\n",
    "        new_h = int(h * scale)\n",
    "        resized_img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        return resized_img\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def resize_and_save_images(original_dataset_path, resized_dataset_path, categories, max_dim=1500):\n",
    "    \"\"\"\n",
    "    Create a resized version of the dataset in a new folder structure \n",
    "    mirroring the original. Only resize if the image exceeds max_dim.\n",
    "    Skip resizing if the image already exists in the desired size.\n",
    "    \n",
    "    Parameters:\n",
    "        original_dataset_path (str): Path to the original dataset.\n",
    "        resized_dataset_path (str): Path to store the resized dataset.\n",
    "        categories (list): List of categories (e.g., ['curved', 'fold', ...]).\n",
    "        max_dim (int): Maximum size for the longest side of the image.\n",
    "    \"\"\"\n",
    "    \n",
    "    # We will replicate the \"distorted\" and \"digital\" structure\n",
    "    for folder_name in ['distorted', 'digital']:\n",
    "        for category in categories:\n",
    "            src_folder = os.path.join(original_dataset_path, folder_name, category)\n",
    "            dst_folder = os.path.join(resized_dataset_path, folder_name, category)\n",
    "            \n",
    "            if not os.path.exists(src_folder):\n",
    "                print(f\"Source folder not found: {src_folder}\")\n",
    "                continue\n",
    "            \n",
    "            # Create destination folder if it doesn't exist\n",
    "            os.makedirs(dst_folder, exist_ok=True)\n",
    "            \n",
    "            # Iterate over all images in the source folder\n",
    "            for file_name in os.listdir(src_folder):\n",
    "                src_img_path = os.path.join(src_folder, file_name)\n",
    "                dst_img_path = os.path.join(dst_folder, file_name)\n",
    "                \n",
    "                # If the file already exists in the resized dataset, \n",
    "                # we can skip reprocessing it\n",
    "                if os.path.exists(dst_img_path):\n",
    "                    # Optional: You could check if it's already under max_dim\n",
    "                    # by reading the resized image and verifying. \n",
    "                    # But here, we assume if it exists, it's already correct.\n",
    "                    continue\n",
    "                \n",
    "                # Read the original image\n",
    "                img = cv2.imread(src_img_path, cv2.IMREAD_COLOR)\n",
    "                if img is None:\n",
    "                    print(f\"Could not read image: {src_img_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # Resize if needed\n",
    "                resized_img = resize_image_if_needed(img, max_dim=max_dim)\n",
    "                \n",
    "                # Save the resized image\n",
    "                cv2.imwrite(dst_img_path, resized_img)\n",
    "\n",
    "    print(\"Resizing completed. Check your resized dataset at:\", resized_dataset_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Original and Resized Images\n",
    "\n",
    "This function visually compares original and resized images to ensure proper scaling. It selects the first image from each category in the `distorted` folder, loads both versions, and displays them side by side.\n",
    "\n",
    "Original images might have varying dimensions, while resized ones are adjusted to fit within `max_dim`. Image dimensions are shown in titles for verification. This step helps confirm that resizing maintains structural integrity before further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_original_and_resized(original_dataset_path, resized_dataset_path, categories):\n",
    "    \"\"\"\n",
    "    Display the original image and the resized image side by side \n",
    "    for a quick comparison.\n",
    "    \n",
    "    Parameters:\n",
    "        original_dataset_path (str): Path to the original dataset.\n",
    "        resized_dataset_path (str): Path to the resized dataset.\n",
    "        categories (list): List of categories.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for i, category in enumerate(categories):\n",
    "        # We'll just pick the first file in each category's \"distorted\" folder\n",
    "        # for demonstration. Adjust as needed.\n",
    "        src_folder = os.path.join(original_dataset_path, 'distorted', category)\n",
    "        dst_folder = os.path.join(resized_dataset_path, 'distorted', category)\n",
    "        \n",
    "        if not os.path.exists(src_folder) or not os.path.exists(dst_folder):\n",
    "            continue\n",
    "        \n",
    "        files_in_src = os.listdir(src_folder)\n",
    "        if not files_in_src:\n",
    "            continue\n",
    "        \n",
    "        # Pick the first image\n",
    "        file_name = files_in_src[0]\n",
    "        src_img_path = os.path.join(src_folder, file_name)\n",
    "        dst_img_path = os.path.join(dst_folder, file_name)\n",
    "        \n",
    "        # Load original and resized images\n",
    "        original_img = cv2.imread(src_img_path, cv2.IMREAD_COLOR)\n",
    "        resized_img = cv2.imread(dst_img_path, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        if original_img is None or resized_img is None:\n",
    "            continue\n",
    "        \n",
    "        # Convert to RGB for plotting\n",
    "        original_rgb = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
    "        resized_rgb = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Get dimensions\n",
    "        o_h, o_w = original_img.shape[:2]\n",
    "        r_h, r_w = resized_img.shape[:2]\n",
    "        \n",
    "        # Plot original\n",
    "        plt.subplot(2, len(categories), i+1)\n",
    "        plt.imshow(original_rgb)\n",
    "        plt.title(f\"Original: {category}\\n{o_w}x{o_h}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Plot resized\n",
    "        plt.subplot(2, len(categories), i+1+len(categories))\n",
    "        plt.imshow(resized_rgb)\n",
    "        plt.title(f\"Resized: {category}\\n{r_w}x{r_h}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_path = dataset_path\n",
    "resized_dataset_path  = '/Users/demir/Desktop/Assignment1/WarpDoc_resized'\n",
    "categories = ['curved', 'fold', 'incomplete', 'perspective', 'random', 'rotate']\n",
    "\n",
    "# Pictures resizing\n",
    "resize_and_save_images(\n",
    "    original_dataset_path=original_dataset_path, \n",
    "    resized_dataset_path=resized_dataset_path, \n",
    "    categories=categories,\n",
    "    max_dim=1500  # Limit on the longest edge on 1500 pixels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Comparison of original and resized pictures\n",
    "compare_original_and_resized(\n",
    "    original_dataset_path=original_dataset_path, \n",
    "    resized_dataset_path=resized_dataset_path, \n",
    "    categories=categories\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Hough Transform Testing\n",
    "\n",
    "In this step, we **use OpenCV's built-in Hough Transform implementation** to analyze its efficiency and optimize parameters before implementing our own version. Although using external functions violates the assignment's requirement to write our own methods, **this test is crucial for understanding how an optimal Hough Transform performs** and tuning hyperparameters effectively.\n",
    "\n",
    "The function detects text-aligned lines by:\n",
    "1. Converting the image to grayscale and applying Gaussian blur.\n",
    "2. Performing Canny edge detection, followed by dilation to enhance edges.\n",
    "3. Using **Probabilistic Hough Transform** to detect potential lines.\n",
    "4. Filtering lines based on **angle and length** to keep only near-horizontal segments.\n",
    "5. Displaying the detected edges and filtered lines alongside the original image.\n",
    "\n",
    "This step allows us to **experiment with different threshold values efficiently** and ensures our custom implementation will be well-calibrated for real-world document distortions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lines_for_text(image_path,\n",
    "                          canny_thresh1=80,\n",
    "                          canny_thresh2=200,\n",
    "                          pht_threshold=60,\n",
    "                          min_line_length=30,\n",
    "                          max_line_gap=5,\n",
    "                          angle_tol=20,\n",
    "                          length_tol=30):\n",
    "    \"\"\"\n",
    "    1) Preprocess (grayscale, blur, canny)\n",
    "    2) Optionally dilate edges\n",
    "    3) Probabilistic Hough\n",
    "    4) Filter lines by angle and length\n",
    "    \"\"\"\n",
    "    # Load image\n",
    "    original = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    if original is None:\n",
    "        raise ValueError(f\"Cannot read image: {image_path}\")\n",
    "    \n",
    "    gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Edges\n",
    "    edges = cv2.Canny(blurred, canny_thresh1, canny_thresh2)\n",
    "    \n",
    "    # (Optional) Dilate to connect broken text edges\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "    \n",
    "    # Probabilistic Hough\n",
    "    lines_p = cv2.HoughLinesP(edges, 1, np.pi/180, pht_threshold,\n",
    "                              minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "    \n",
    "    filtered_segments = []\n",
    "    if lines_p is not None:\n",
    "        for line in lines_p:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            dx = x2 - x1\n",
    "            dy = y2 - y1\n",
    "            angle_deg = abs(math.degrees(math.atan2(dy, dx)))\n",
    "            length = math.hypot(dx, dy)\n",
    "            \n",
    "            if length < length_tol:\n",
    "                continue\n",
    "            \n",
    "            # Relaxed angle check for text lines\n",
    "            if (angle_deg < angle_tol) or (abs(angle_deg - 180) < angle_tol):\n",
    "                # keep lines near horizontal\n",
    "                filtered_segments.append((x1, y1, x2, y2))\n",
    "    \n",
    "    return original, edges, filtered_segments\n",
    "\n",
    "def draw_segments(image, segments):\n",
    "    out = image.copy()\n",
    "    for (x1, y1, x2, y2) in segments:\n",
    "        cv2.line(out, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    return out\n",
    "\n",
    "def show_text_lines(resized_dataset_path, category='perspective'):\n",
    "    # 1) Select a sample\n",
    "    folder = os.path.join(resized_dataset_path, 'distorted', category)\n",
    "    files = os.listdir(folder)\n",
    "    if not files:\n",
    "        print(f\"No images in {folder}\")\n",
    "        return\n",
    "    image_path = os.path.join(folder, files[11])\n",
    "    \n",
    "    # 2) Detect lines with more lenient settings\n",
    "    original, edges, segments = detect_lines_for_text(\n",
    "        image_path,\n",
    "        canny_thresh1=100,\n",
    "        canny_thresh2=300,\n",
    "        pht_threshold=100,     # lower threshold -> more lines\n",
    "        min_line_length=30,   # smaller -> shorter lines pass\n",
    "        max_line_gap=30,\n",
    "        angle_tol=360,         # bigger angle tolerance -> lines that are not perfectly horizontal\n",
    "        length_tol=100         # smaller length filter -> keep short lines\n",
    "    )\n",
    "    \n",
    "    # 3) Draw lines\n",
    "    lines_img = draw_segments(original, segments)\n",
    "    \n",
    "    # 4) Visualize\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(edges, cmap='gray')\n",
    "    plt.title(\"Edges (with dilation)\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(cv2.cvtColor(lines_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Filtered Lines: {len(segments)} segments\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "resized_dataset_path = '/Users/demir/Desktop/Assignment1/WarpDoc_resized'\n",
    "show_text_lines(resized_dataset_path, category='perspective')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Hough Transform and Region-based Line Detection\n",
    "\n",
    "This step **implements a custom version of Probabilistic Hough Transform**, following OpenCV’s `HoughLinesP` logic but written from scratch. Instead of using OpenCV’s built-in function, we manually compute an **accumulator matrix**, detect peaks, and extract line segments based on their spatial continuity.\n",
    "\n",
    "A **document mask** is created to isolate the paper region and ignore background noise. The process follows:\n",
    "1. Convert to grayscale and apply thresholding to detect bright document regions.\n",
    "2. Use morphological closing to clean noise.\n",
    "3. Extract the largest contour and create a mask.\n",
    "4. Apply **Canny edge detection** and mask edges to focus only on the document.\n",
    "5. Use our **custom Hough Transform implementation** to detect line segments.\n",
    "6. Draw and visualize detected lines over the masked region.\n",
    "\n",
    "This method ensures **better performance in real-world distortions**, especially for curved and folded documents, improving the accuracy of document rectification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myHoughLinesP_standard_topK(edges,\n",
    "                                rho=1,\n",
    "                                theta=np.pi/180,\n",
    "                                threshold=50,\n",
    "                                minLineLength=50,\n",
    "                                maxLineGap=10,\n",
    "                                top_k=50):\n",
    "    \"\"\"\n",
    "    Geliştirilmiş Hough kodu:\n",
    "    1) Klasik accumulator hesapla (rho, theta).\n",
    "    2) threshold üstündeki tüm pikleri topla, 'oy sayısı'na göre sırala.\n",
    "    3) Yalnızca ilk top_k pik için çizgi segmenti bul.\n",
    "    4) Segmentleri, projeksiyon farkı maxLineGap'tan büyükse ayır,\n",
    "       uzunluğu minLineLength'ten büyük olanları kaydet.\n",
    "    \"\"\"\n",
    "    y_idxs, x_idxs = np.nonzero(edges)\n",
    "    if len(x_idxs) == 0:\n",
    "        return None\n",
    "    \n",
    "    height, width = edges.shape\n",
    "    diag_len = int(np.ceil(np.sqrt(height**2 + width**2)))  # max rho\n",
    "    \n",
    "    # 1) theta, rho dizileri\n",
    "    thetas = np.arange(0, np.pi, theta)\n",
    "    cos_thetas = np.cos(thetas)\n",
    "    sin_thetas = np.sin(thetas)\n",
    "    num_thetas = len(thetas)\n",
    "\n",
    "    num_rhos = int(2*diag_len/rho) + 1\n",
    "    rhos_arr = np.linspace(-diag_len, diag_len, num_rhos)\n",
    "\n",
    "    # 2) accumulator\n",
    "    Xcol = x_idxs.reshape(-1,1)\n",
    "    Ycol = y_idxs.reshape(-1,1)\n",
    "    rho_mat = Xcol*cos_thetas + Ycol*sin_thetas\n",
    "    rho_idx_mat = np.round((rho_mat+diag_len)/rho).astype(np.int32)\n",
    "    \n",
    "    N = len(Xcol)\n",
    "    theta_idx_flat = np.tile(np.arange(num_thetas), N)\n",
    "    rho_idx_flat   = rho_idx_mat.flatten()\n",
    "    acc_1d = np.ravel_multi_index((rho_idx_flat, theta_idx_flat),\n",
    "                                  (num_rhos, num_thetas))\n",
    "    counts = np.bincount(acc_1d, minlength=num_rhos*num_thetas)\n",
    "    accumulator = counts.reshape((num_rhos, num_thetas))\n",
    "\n",
    "    # 3) threshold üstündeki pikleri bul\n",
    "    peaks = []\n",
    "    for r_i in range(num_rhos):\n",
    "        for t_i in range(num_thetas):\n",
    "            votes = accumulator[r_i, t_i]\n",
    "            if votes >= threshold:\n",
    "                peaks.append((votes, r_i, t_i))\n",
    "    if not peaks:\n",
    "        return None\n",
    "\n",
    "    # 4) Oylara göre sırala, ilk top_k al\n",
    "    peaks.sort(key=lambda x: x[0], reverse=True)\n",
    "    peaks = peaks[:top_k]\n",
    "\n",
    "    lines = []\n",
    "    for (votes, r_i, t_i) in peaks:\n",
    "        rho_val = rhos_arr[r_i]\n",
    "        theta_val = thetas[t_i]\n",
    "        c = math.cos(theta_val)\n",
    "        s = math.sin(theta_val)\n",
    "\n",
    "        # Kenar noktalarını topla\n",
    "        close_points = []\n",
    "        for (x, y) in zip(x_idxs, y_idxs):\n",
    "            d = abs(x*c + y*s - rho_val)\n",
    "            # Tolerans ~1 piksel\n",
    "            if d < 1.0:\n",
    "                close_points.append((x, y))\n",
    "        if len(close_points)<2:\n",
    "            continue\n",
    "        \n",
    "        # Projeksiyon\n",
    "        close_points = np.array(close_points)\n",
    "        t_vals = close_points[:,0]*c + close_points[:,1]*s\n",
    "        sort_idx = np.argsort(t_vals)\n",
    "        close_points = close_points[sort_idx]\n",
    "        t_vals      = t_vals[sort_idx]\n",
    "\n",
    "        # Segment parçalama\n",
    "        start_idx = 0\n",
    "        for i in range(1, len(close_points)):\n",
    "            gap = t_vals[i] - t_vals[i-1]\n",
    "            if gap> maxLineGap:\n",
    "                seg_pts = close_points[start_idx:i]\n",
    "                seg = _create_line_segment(seg_pts, c, s, minLineLength)\n",
    "                if seg is not None:\n",
    "                    lines.append(seg)\n",
    "                start_idx= i\n",
    "        # son segment\n",
    "        seg_pts = close_points[start_idx:]\n",
    "        seg = _create_line_segment(seg_pts, c, s, minLineLength)\n",
    "        if seg is not None:\n",
    "            lines.append(seg)\n",
    "\n",
    "    if not lines:\n",
    "        return None\n",
    "    return np.array(lines)\n",
    "\n",
    "def _create_line_segment(points, cos_t, sin_t, minLineLength):\n",
    "    \"\"\"\n",
    "    from your code: if length>=minLineLength => return (x_min, y_min, x_max, y_max)\n",
    "    \"\"\"\n",
    "    if len(points)<2:\n",
    "        return None\n",
    "    xs = points[:,0]\n",
    "    ys = points[:,1]\n",
    "    x_min, y_min = np.min(points, axis=0)\n",
    "    x_max, y_max = np.max(points, axis=0)\n",
    "    length = math.hypot(x_max-x_min, y_max-y_min)\n",
    "    if length< minLineLength:\n",
    "        return None\n",
    "    return (int(x_min), int(y_min), int(x_max), int(y_max))\n",
    "\n",
    "\n",
    "def find_document_mask(gray_image):\n",
    "    \"\"\"\n",
    "    Creates a mask for the document region, assuming the document is white.\n",
    "\n",
    "    Steps:\n",
    "    1) Apply a high-threshold binary filter to capture bright document regions.\n",
    "    2) Use morphological closing to remove noise.\n",
    "    3) Identify the largest contour with four corners (approx 4).\n",
    "    4) Generate and return the mask.\n",
    "    \"\"\"\n",
    "    # 1) Fixed threshold\n",
    "    _, bin_img = cv2.threshold(gray_image, 30, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 2) Closing operation\n",
    "    kernel = np.ones((7, 7), np.uint8)\n",
    "    bin_img = cv2.morphologyEx(bin_img, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    \n",
    "    # 3) Find contours\n",
    "    contours, _ = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    \n",
    "    # Identify the largest contour by area\n",
    "    max_area = 0\n",
    "    best_approx = None\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > max_area:\n",
    "            # Approximate contour polygon\n",
    "            epsilon = 0.02 * cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "            max_area = area\n",
    "            best_approx = approx\n",
    "    \n",
    "    if best_approx is None:\n",
    "        return None\n",
    "    \n",
    "    mask = np.zeros_like(gray_image, dtype=np.uint8)\n",
    "    cv2.drawContours(mask, [best_approx], -1, 255, -1)\n",
    "    return mask\n",
    "\n",
    "def detect_lines_for_text_with_mask(image_path,\n",
    "                                    canny_thresh1=100,\n",
    "                                    canny_thresh2=200,\n",
    "                                    pht_threshold=80,\n",
    "                                    min_line_length=30,\n",
    "                                    max_line_gap=30):\n",
    "    \"\"\"\n",
    "    1) Load the image\n",
    "    2) Convert to grayscale and create a mask (ROI)\n",
    "    3) Detect edges and apply the mask\n",
    "    4) Detect lines using HoughLines (myHoughLinesP_standard)\n",
    "    \"\"\"\n",
    "    original = cv2.imread(image_path)\n",
    "    if original is None:\n",
    "        raise ValueError(f\"Cannot read image: {image_path}\")\n",
    "\n",
    "    gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n",
    "    # Document mask\n",
    "    doc_mask = find_document_mask(gray)\n",
    "    if doc_mask is None:\n",
    "        print(\"No contour found. Using entire image as ROI.\")\n",
    "        doc_mask = np.ones_like(gray, dtype=np.uint8)*255  \n",
    "\n",
    "    # Edge detection\n",
    "    blurred = cv2.GaussianBlur(gray, (7,7), 0)\n",
    "    edges = cv2.Canny(blurred, canny_thresh1, canny_thresh2)\n",
    "\n",
    "    # Apply mask to edges\n",
    "    masked_edges = cv2.bitwise_and(edges, edges, mask=doc_mask)\n",
    "\n",
    "    # Detect Hough lines\n",
    "    lines = myHoughLinesP_standard_topK(masked_edges,\n",
    "                                   rho=1,\n",
    "                                   theta=np.pi/180,\n",
    "                                   threshold=pht_threshold,\n",
    "                                   minLineLength=min_line_length,\n",
    "                                   maxLineGap=max_line_gap,\n",
    "                                   top_k=50)\n",
    "    return original, edges, doc_mask, masked_edges, lines\n",
    "\n",
    "def draw_segments(image, segments, color=(0,255,0), thickness=2):\n",
    "    \"\"\"\n",
    "    Draws detected line segments on an image.\n",
    "    \"\"\"\n",
    "    out = image.copy()\n",
    "    if segments is None:\n",
    "        return out\n",
    "    for (x1, y1, x2, y2) in segments:\n",
    "        cv2.line(out, (x1, y1), (x2, y2), color, thickness)\n",
    "    return out\n",
    "\n",
    "\n",
    "def show_text_lines_roi(resized_dataset_path, category='perspective'):\n",
    "    folder = os.path.join(resized_dataset_path, 'distorted', category)\n",
    "    files = os.listdir(folder)\n",
    "    if not files:\n",
    "        print(\"No images in\", folder)\n",
    "        return\n",
    "    \n",
    "    image_path = os.path.join(folder, files[11])\n",
    "\n",
    "    original, edges, doc_mask, masked_edges, lines = detect_lines_for_text_with_mask(\n",
    "        image_path,\n",
    "        canny_thresh1=100,\n",
    "        canny_thresh2=200,\n",
    "        pht_threshold=80,\n",
    "        min_line_length=100,\n",
    "        max_line_gap=10\n",
    "    )\n",
    "\n",
    "    lines_img = draw_segments(original, lines)\n",
    "\n",
    "    plt.figure(figsize=(14,6))\n",
    "\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.imshow(doc_mask, cmap=\"gray\")\n",
    "    plt.title(\"Document Mask (ROI)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.imshow(edges, cmap=\"gray\")\n",
    "    plt.title(\"Canny (unmasked)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.imshow(masked_edges, cmap=\"gray\")\n",
    "    plt.title(\"Masked Edges\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(2,3,5)\n",
    "    seg_count = len(lines) if lines is not None else 0\n",
    "    plt.imshow(cv2.cvtColor(lines_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Hough Lines: {seg_count}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Kullanım:\n",
    "resized_dataset_path = '/Users/demir/Desktop/Assignment1/WarpDoc_resized'\n",
    "show_text_lines_roi(resized_dataset_path, category='perspective')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANSAC-based Line Refinement\n",
    "\n",
    "This section applies **RANSAC (Random Sample Consensus)** to refine the line segments detected by the Hough Transform. Hough-detected lines often contain noise and outliers, so **RANSAC helps find the most consistent line by filtering inliers**.\n",
    "\n",
    "1. **`ransac_line_fitting()`**  \n",
    "   - Selects two random points from the edge image and computes a candidate line.\n",
    "   - Counts how many points (inliers) fit the line within a distance threshold.\n",
    "   - Repeats for multiple iterations, keeping the best line with the most inliers.\n",
    "\n",
    "2. **`refine_lines_with_ransac()`**  \n",
    "   - Uses RANSAC to re-fit each detected Hough line.\n",
    "   - Collects nearby edge points and removes weak/noisy lines.\n",
    "   - Converts detected lines into a more robust **(a, b, c) format**, improving document rectification.\n",
    "\n",
    "By using **RANSAC**, this step ensures that only the most reliable line segments are used, reducing distortion and improving perspective correction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Filtering, Grouping, and Refinement\n",
    "\n",
    "To improve the robustness of the detected lines, several filtering and refinement steps were implemented.\n",
    "\n",
    "1. **Filtering Short Lines**  \n",
    "   - The function `filter_lines_by_length()` removes lines shorter than a given ratio of the image size. This helps eliminate small, irrelevant segments.\n",
    "\n",
    "2. **Grouping Lines by Angle**  \n",
    "   - `group_lines_by_angle()` clusters lines that have similar orientations. This ensures that vertical and horizontal edges are grouped separately.\n",
    "\n",
    "3. **Merging Collinear Lines**  \n",
    "   - `merge_collinear_lines()` combines nearby, nearly parallel lines into a single segment. It considers both **angle similarity** and **spatial proximity**.\n",
    "\n",
    "4. **Filtering by Document Mask**  \n",
    "   - `filter_lines_by_mask_coverage()` removes lines that do not sufficiently overlap with the document region, ensuring that detected lines belong to the document.\n",
    "\n",
    "5. **RANSAC-based Refinement**  \n",
    "   - `ransac_line_fitting()` refits line segments to **eliminate outliers** and find the most consistent line model.\n",
    "   - `refine_lines_with_ransac()` selects candidate edge points near each line and applies **RANSAC** for better fitting.\n",
    "\n",
    "6. **Fast Line Refinement Pipeline**  \n",
    "   - `fast_ransac_pipeline()` integrates all the above steps, including line length filtering, angle-based grouping, collinear merging, document mask filtering, and RANSAC-based refinement.\n",
    "   - The pipeline ensures that only **meaningful document boundaries** are considered for further perspective correction.\n",
    "\n",
    "These steps significantly **improve the reliability of document boundary detection** and make the perspective transformation more robust.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_lines_by_length(lines, img_width, img_height, min_length_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Filters out short lines.\n",
    "    Example: min_length_ratio=0.1 ->\n",
    "             line length >= 0.1 * max(img_width, img_height)\n",
    "    \"\"\"\n",
    "    if lines is None:\n",
    "        return []\n",
    "    min_length = min_length_ratio * max(img_width, img_height)\n",
    "    \n",
    "    filtered = []\n",
    "    for (x1, y1, x2, y2) in lines:\n",
    "        length = math.hypot(x2 - x1, y2 - y1)\n",
    "        if length >= min_length:\n",
    "            filtered.append((x1, y1, x2, y2))\n",
    "    return filtered\n",
    "\n",
    "def compute_line_angle_deg(x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Returns the angle of the line in the range [0, 180) degrees.\n",
    "    \"\"\"\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "    angle_rad = math.atan2(dy, dx)\n",
    "    return math.degrees(angle_rad) % 180\n",
    "\n",
    "def group_lines_by_angle(lines, angle_thresh=12.0):\n",
    "    \"\"\"\n",
    "    Groups lines with similar angles.\n",
    "    angle_thresh => Lines with an angle difference less than this are grouped together.\n",
    "    Returns: [ [line1, line2, ...], [line3, line4, ...], ... ]\n",
    "    \"\"\"\n",
    "    groups = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line\n",
    "        angle = compute_line_angle_deg(x1, y1, x2, y2)\n",
    "        \n",
    "        placed = False\n",
    "        for g in groups:\n",
    "            avg_angle = g['avg_angle']\n",
    "            if abs(angle - avg_angle) < angle_thresh:\n",
    "                g['lines'].append(line)\n",
    "                angles = [compute_line_angle_deg(*ln) for ln in g['lines']]\n",
    "                g['avg_angle'] = np.mean(angles)\n",
    "                placed = True\n",
    "                break\n",
    "        if not placed:\n",
    "            groups.append({'lines': [line], 'avg_angle': angle})\n",
    "    \n",
    "    return [g['lines'] for g in groups]\n",
    "\n",
    "def lines_are_close(x1i, y1i, x2i, y2i, x1j, y1j, x2j, y2j, dist_thresh):\n",
    "    \"\"\"\n",
    "    Checks if two line segments are close (collinear).\n",
    "    A simple approach: Distance between midpoints of the lines should be < dist_thresh.\n",
    "    \"\"\"\n",
    "    mxi = (x1i + x2i) / 2\n",
    "    myi = (y1i + y2i) / 2\n",
    "    mxj = (x1j + x2j) / 2\n",
    "    myj = (y1j + y2j) / 2\n",
    "    \n",
    "    dist = math.hypot(mxj - mxi, myj - myi)\n",
    "    return dist < dist_thresh\n",
    "\n",
    "def merge_collinear_lines(lines, dist_thresh=8.0, angle_thresh=8.0):\n",
    "    \"\"\"\n",
    "    Merges collinear and closely spaced lines within a group.\n",
    "    dist_thresh: Maximum midpoint distance between lines to be considered close.\n",
    "    angle_thresh: Maximum angle difference (in degrees) to be considered similar.\n",
    "    \"\"\"\n",
    "    merged = []\n",
    "    used = [False] * len(lines)\n",
    "    \n",
    "    for i in range(len(lines)):\n",
    "        if used[i]:\n",
    "            continue\n",
    "        x1i, y1i, x2i, y2i = lines[i]\n",
    "        ref_angle = compute_line_angle_deg(x1i, y1i, x2i, y2i)\n",
    "        ref_points = [(x1i, y1i), (x2i, y2i)]\n",
    "        \n",
    "        used[i] = True\n",
    "        \n",
    "        for j in range(i+1, len(lines)):\n",
    "            if used[j]:\n",
    "                continue\n",
    "            x1j, y1j, x2j, y2j = lines[j]\n",
    "            angle_j = compute_line_angle_deg(x1j, y1j, x2j, y2j)\n",
    "            \n",
    "            angle_diff = abs(angle_j - ref_angle)\n",
    "            angle_diff = min(angle_diff, 180 - angle_diff)  # Normalize within 180 degrees\n",
    "            if angle_diff < angle_thresh:\n",
    "                if lines_are_close(x1i, y1i, x2i, y2i, x1j, y1j, x2j, y2j, dist_thresh):\n",
    "                    ref_points.append((x1j, y1j))\n",
    "                    ref_points.append((x2j, y2j))\n",
    "                    used[j] = True\n",
    "        \n",
    "        ref_points = np.array(ref_points)\n",
    "        minx, miny = np.min(ref_points, axis=0)\n",
    "        maxx, maxy = np.max(ref_points, axis=0)\n",
    "        merged.append((int(minx), int(miny), int(maxx), int(maxy)))\n",
    "    \n",
    "    return merged\n",
    "\n",
    "def filter_lines_by_mask_coverage(lines, doc_mask, coverage_thresh=0.3, num_samples=20):\n",
    "    \"\"\"\n",
    "    Filters lines based on the percentage of pixels inside the doc_mask.\n",
    "    coverage_thresh=0.3 => At least 30% of the sampled points along the line must be inside the mask.\n",
    "    \"\"\"\n",
    "    if doc_mask is None:\n",
    "        return lines  # If no mask is provided, return lines unchanged.\n",
    "    \n",
    "    h, w = doc_mask.shape[:2]\n",
    "    good_lines = []\n",
    "    \n",
    "    for (x1, y1, x2, y2) in lines:\n",
    "        length = math.hypot(x2 - x1, y2 - y1)\n",
    "        if length < 1e-6:\n",
    "            continue\n",
    "        \n",
    "        # Sample num_samples points along the line\n",
    "        covered = 0\n",
    "        for s in range(num_samples):\n",
    "            t = s / (num_samples - 1)\n",
    "            xs = int(x1 + (x2 - x1) * t)\n",
    "            ys = int(y1 + (y2 - y1) * t)\n",
    "            if 0 <= xs < w and 0 <= ys < h:\n",
    "                # If doc_mask[ys, xs] > 0, the point is inside the mask\n",
    "                if doc_mask[ys, xs] > 0:\n",
    "                    covered += 1\n",
    "        \n",
    "        coverage = covered / num_samples\n",
    "        if coverage >= coverage_thresh:\n",
    "            good_lines.append((x1, y1, x2, y2))\n",
    "    \n",
    "    return good_lines\n",
    "\n",
    "def ransac_line_fitting(points, dist_thresh=3.0, max_iters=1000, min_inliers=20):\n",
    "    \"\"\"\n",
    "    Applies RANSAC to find the best-fitting line for a set of (x, y) points.\n",
    "    Returns the line in (a, b, c) form.\n",
    "    dist_thresh increased to 3.0 for a more relaxed inlier threshold.\n",
    "    \"\"\"\n",
    "    import random\n",
    "    if len(points) < min_inliers:\n",
    "        return None, []\n",
    "    \n",
    "    best_line = None\n",
    "    best_inliers = []\n",
    "    best_count = 0\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        p1, p2 = random.sample(list(points), 2)\n",
    "        x1, y1 = p1\n",
    "        x2, y2 = p2\n",
    "        if x1 == x2 and y1 == y2:\n",
    "            continue\n",
    "        \n",
    "        # Compute the line equation in ax + by + c = 0 form\n",
    "        a = y2 - y1\n",
    "        b = x1 - x2\n",
    "        c = x2 * y1 - x1 * y2\n",
    "        norm = math.hypot(a, b)\n",
    "        if norm < 1e-6:\n",
    "            continue\n",
    "        a /= norm\n",
    "        b /= norm\n",
    "        c /= norm\n",
    "        \n",
    "        inliers_temp = []\n",
    "        for (x, y) in points:\n",
    "            dist = abs(a * x + b * y + c)\n",
    "            if dist < dist_thresh:\n",
    "                inliers_temp.append((x, y))\n",
    "        \n",
    "        if len(inliers_temp) > best_count:\n",
    "            best_count = len(inliers_temp)\n",
    "            best_inliers = inliers_temp\n",
    "            best_line = (a, b, c)\n",
    "    \n",
    "    if best_line is None or best_count < min_inliers:\n",
    "        return None, []\n",
    "    return best_line, best_inliers\n",
    "\n",
    "def refine_lines_with_ransac(lines, edge_image, candidate_dist=8.0, ransac_dist=3.0, max_iters=1000, min_inliers=20):\n",
    "    \"\"\"\n",
    "    Applies RANSAC to refine each detected line using nearby edge points.\n",
    "    candidate_dist => Threshold to consider a point as near a line.\n",
    "    ransac_dist => Inlier distance threshold for RANSAC.\n",
    "    \"\"\"\n",
    "    if not lines:\n",
    "        return []\n",
    "    \n",
    "    pts_y, pts_x = np.nonzero(edge_image)\n",
    "    all_points = np.column_stack((pts_x, pts_y))\n",
    "    \n",
    "    refined = []\n",
    "    for (x1, y1, x2, y2) in lines:\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        length = math.hypot(dx, dy)\n",
    "        if length < 1e-6:\n",
    "            continue\n",
    "        \n",
    "        # Compute initial normal form (a, b, c) of the line\n",
    "        a_0 = dy\n",
    "        b_0 = -dx\n",
    "        c_0 = dx * y1 - dy * x1\n",
    "        norm_0 = math.hypot(a_0, b_0)\n",
    "        if norm_0 < 1e-6:\n",
    "            continue\n",
    "        a_0 /= norm_0\n",
    "        b_0 /= norm_0\n",
    "        c_0 /= norm_0\n",
    "        \n",
    "        # Collect candidate inlier points\n",
    "        candidate_pts = []\n",
    "        for (px, py) in all_points:\n",
    "            dist = abs(a_0 * px + b_0 * py + c_0)\n",
    "            if dist < candidate_dist:  # 8 pixels\n",
    "                candidate_pts.append((px, py))\n",
    "        \n",
    "        if len(candidate_pts) < min_inliers:\n",
    "            continue\n",
    "        \n",
    "        candidate_pts = np.array(candidate_pts)\n",
    "        best_line, inliers = ransac_line_fitting(candidate_pts, dist_thresh=ransac_dist,\n",
    "                                                 max_iters=max_iters, min_inliers=min_inliers)\n",
    "        if best_line is not None:\n",
    "            refined.append(best_line)\n",
    "    return refined\n",
    "\n",
    "def fast_ransac_pipeline(lines, edge_image, img_width, img_height, doc_mask=None):\n",
    "    \"\"\"\n",
    "    Optimized pipeline for line filtering and refinement:\n",
    "    1) Filter out short lines using a lower min_length_ratio.\n",
    "    2) Group lines based on angle tolerance.\n",
    "    3) Merge collinear lines using adjusted dist_thresh and angle_thresh.\n",
    "    4) (Optional) Apply document mask filtering for coverage.\n",
    "    5) Filter short lines again after merging.\n",
    "    6) Select the top 12 longest lines.\n",
    "    7) Apply RANSAC refinement with increased candidate_dist and ransac_dist.\n",
    "    \"\"\"\n",
    "    # 1) Filter short lines\n",
    "    lines_filt = filter_lines_by_length(lines, img_width, img_height, min_length_ratio=0.1)\n",
    "    if not lines_filt:\n",
    "        print(\"No lines after length filtering.\")\n",
    "        return []\n",
    "    \n",
    "    # 2) Group lines by angle\n",
    "    angle_groups = group_lines_by_angle(lines_filt, angle_thresh=12.0)\n",
    "    \n",
    "    # 3) Merge collinear lines\n",
    "    merged_lines = []\n",
    "    for grp in angle_groups:\n",
    "        merged = merge_collinear_lines(grp, dist_thresh=8.0, angle_thresh=8.0)\n",
    "        merged_lines.extend(merged)\n",
    "    \n",
    "    # 4) (Optional) Apply document mask filtering\n",
    "    if doc_mask is not None:\n",
    "        merged_lines = filter_lines_by_mask_coverage(merged_lines, doc_mask, coverage_thresh=0.3, num_samples=20)\n",
    "    \n",
    "    # 5) Filter short lines again\n",
    "    merged_lines = filter_lines_by_length(merged_lines, img_width, img_height, min_length_ratio=0.1)\n",
    "    \n",
    "    if not merged_lines:\n",
    "        print(\"No lines after merging & coverage filtering.\")\n",
    "        return []\n",
    "    \n",
    "    # 6) Select the top 12 longest lines\n",
    "    merged_lines = sorted(merged_lines, key=lambda ln: math.hypot(ln[2]-ln[0], ln[3]-ln[1]), reverse=True)\n",
    "    topN = 35\n",
    "    final_lines = merged_lines[:topN]\n",
    "    \n",
    "    # 7) RANSAC-based refinement\n",
    "    refined = refine_lines_with_ransac(final_lines, edge_image,\n",
    "                                       candidate_dist=8.0,  # Candidate points selection threshold\n",
    "                                       ransac_dist=3.0,     # Inlier distance threshold for RANSAC\n",
    "                                       max_iters=1000,\n",
    "                                       min_inliers=20)\n",
    "    \n",
    "    return refined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Refined RANSAC Lines\n",
    "\n",
    "This function applies the **RANSAC pipeline** to refine document edges and visualize the results.\n",
    "\n",
    "1. **Line Detection using Hough Transform**  \n",
    "   - `detect_lines_for_text_with_mask()` extracts raw lines from the edge image.\n",
    "   - If no lines are found, the process stops.\n",
    "\n",
    "2. **Applying RANSAC Refinement**  \n",
    "   - `fast_ransac_pipeline()` is used to refine detected lines, ensuring that only meaningful segments remain.\n",
    "\n",
    "3. **Conversion from (a, b, c) to (x1, y1, x2, y2)**  \n",
    "   - Since refined lines are returned in **(a, b, c) format**, they must be converted back to **(x1, y1, x2, y2)** for visualization.\n",
    "   - `draw_refined_lines()` computes the intersection of each line with the image borders.\n",
    "\n",
    "4. **Visualization**  \n",
    "   - Displays:\n",
    "     - **Original Image**\n",
    "     - **Masked Edge Detection**\n",
    "     - **Final Refined Lines from RANSAC**\n",
    "\n",
    "This method effectively **removes outliers and enhances document boundary detection**, leading to a more accurate perspective correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_text_lines_roi_ransac(resized_dataset_path, category='perspective'):\n",
    "    \"\"\"\n",
    "    Applies the RANSAC pipeline to refine document text lines and visualize the results.\n",
    "    \"\"\"\n",
    "    folder = os.path.join(resized_dataset_path, 'distorted', category)\n",
    "    files = os.listdir(folder)\n",
    "    if not files:\n",
    "        print(\"No images in\", folder)\n",
    "        return\n",
    "    \n",
    "    image_path = os.path.join(folder, files[11])\n",
    "    \n",
    "    # 1) Normal workflow: Detect initial lines\n",
    "    original, edges, doc_mask, masked_edges, lines = detect_lines_for_text_with_mask(\n",
    "        image_path,\n",
    "        canny_thresh1=100,\n",
    "        canny_thresh2=200,\n",
    "        pht_threshold=120,\n",
    "        min_line_length=100,\n",
    "        max_line_gap=10\n",
    "    )\n",
    "    \n",
    "    # 2) Apply the RANSAC pipeline if lines were found\n",
    "    if lines is None:\n",
    "        print(\"No lines found by Hough.\")\n",
    "        return\n",
    "    \n",
    "    h, w = masked_edges.shape\n",
    "    \n",
    "    # 3) Run the RANSAC-based refinement pipeline\n",
    "    refined_lines = fast_ransac_pipeline(lines, masked_edges, w, h)\n",
    "    \n",
    "    print(\"Refined lines (a, b, c) count:\", len(refined_lines))\n",
    "    \n",
    "    # 4) Convert refined lines (a, b, c) into drawable (x1, y1, x2, y2) format\n",
    "    lines_img = draw_refined_lines(original, refined_lines)\n",
    "    \n",
    "    # 5) Visualization\n",
    "    plt.figure(figsize=(14,6))\n",
    "    \n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(masked_edges, cmap=\"gray\")\n",
    "    plt.title(\"Masked Edges\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(cv2.cvtColor(lines_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Refined RANSAC Lines: {len(refined_lines)}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def draw_refined_lines(image, refined_lines, color=(0,255,0)):\n",
    "    \"\"\"\n",
    "    Converts refined lines in (a, b, c) form into drawable (x1, y1, x2, y2) format.\n",
    "    Since a*x + b*y + c = 0 represents an infinite line, we find its intersections\n",
    "    with the image borders and draw the visible segment.\n",
    "    \"\"\"\n",
    "    out = image.copy()\n",
    "    h, w = out.shape[:2]\n",
    "    for (a, b, c) in refined_lines:\n",
    "        # Compute (x1, y1, x2, y2) based on screen boundaries\n",
    "        # Line equation: a*x + b*y + c = 0\n",
    "        # Solutions:\n",
    "        #   x=0 -> y= -c/b\n",
    "        #   x=w -> y= -(c + a*w)/b\n",
    "        #   y=0 -> x= -c/a\n",
    "        #   y=h -> x= -(c + b*h)/a\n",
    "        pts = []\n",
    "        if abs(b) > 1e-6:\n",
    "            y_at_x0 = -c / b\n",
    "            if 0 <= y_at_x0 <= h:\n",
    "                pts.append((0, int(y_at_x0)))\n",
    "            \n",
    "            y_at_xw = -(c + a * w) / b\n",
    "            if 0 <= y_at_xw <= h:\n",
    "                pts.append((w, int(y_at_xw)))\n",
    "        if abs(a) > 1e-6:\n",
    "            x_at_y0 = -c / a\n",
    "            if 0 <= x_at_y0 <= w:\n",
    "                pts.append((int(x_at_y0), 0))\n",
    "            \n",
    "            x_at_yh = -(c + b * h) / a\n",
    "            if 0 <= x_at_yh <= w:\n",
    "                pts.append((int(x_at_yh), h))\n",
    "        \n",
    "        if len(pts) >= 2:\n",
    "            # Draw the first two valid points as a line\n",
    "            (x1, y1), (x2, y2) = pts[0], pts[1]\n",
    "            cv2.line(out, (x1, y1), (x2, y2), color, 2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_text_lines_roi_ransac('/Users/demir/Desktop/Assignment1/WarpDoc_resized', 'perspective')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Correction and Quality Evaluation\n",
    "\n",
    "This section aims to refine document boundary detection and apply perspective correction to obtain a properly aligned document view. Additionally, the quality of the corrected document is evaluated using the **Structural Similarity Index (SSIM).**\n",
    "\n",
    "### **Key Steps:**\n",
    "1. **Finding the Four Dominant Lines**\n",
    "   - Lines are grouped by angle using `group_abc_lines_by_angle()`.\n",
    "   - The two largest groups are classified as **vertical** and **horizontal**.\n",
    "   - The most extreme lines (leftmost, rightmost, topmost, bottommost) are selected as document edges.\n",
    "\n",
    "2. **Finding Corner Points**\n",
    "   - Line intersections are computed using `intersect_abc()` to determine document corners.\n",
    "   - If any intersection is missing, the process fails.\n",
    "\n",
    "3. **Sorting Corners for Homography**\n",
    "   - The detected corners are sorted into the required **(top-left, top-right, bottom-right, bottom-left)** order using `sort_corners()`.\n",
    "   - This ensures correct transformation.\n",
    "\n",
    "4. **Applying Perspective Warping**\n",
    "   - `warp_document()` computes a perspective transformation using `cv2.getPerspectiveTransform()`.\n",
    "   - The document is rectified into a standard output size.\n",
    "\n",
    "5. **Comparing with Ground Truth (SSIM)**\n",
    "   - The processed image is resized to match the ground-truth dimensions.\n",
    "   - SSIM is computed to measure similarity.\n",
    "\n",
    "### **Challenges & Limitations:**\n",
    "- The method **does not always detect all four document edges correctly**, leading to incomplete warping.\n",
    "- Line detection is **still affected by unwanted background elements**, which sometimes interfere with boundary estimation.\n",
    "- **Highly distorted or curved documents** require further refinement, as straight-line approximations may not be sufficient.\n",
    "- While SSIM provides a numerical similarity measure, **perceptual differences** (e.g., brightness or minor shifts) may still exist.\n",
    "\n",
    "### **Future Work:**\n",
    "- Improve line filtering to ensure that only **document edges** are detected.\n",
    "- Implement a **more adaptive method** for handling non-rectangular documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def line_angle_degrees_abc(a, b, c):\n",
    "    \"\"\"\n",
    "    (a,b,c) -> a*x + b*y + c = 0\n",
    "    Returns the angle of inclination of this line whose normal vector is (a,b) in the range [0..n).\n",
    "    \"\"\"\n",
    "    angle_rad = math.atan2(-a, b)\n",
    "    n = 360\n",
    "    angle_deg = math.degrees(angle_rad) % n\n",
    "    return angle_deg\n",
    "\n",
    "def intersect_abc(line1, line2):\n",
    "    \"\"\"\n",
    "    Intersection of two lines (x, y) or None (parallel).\n",
    "    line1, line2 = (a,b,c) form\n",
    "    \"\"\"\n",
    "    a1, b1, c1 = line1\n",
    "    a2, b2, c2 = line2\n",
    "    denom = a1*b2 - a2*b1\n",
    "    if abs(denom) < 1e-8:\n",
    "        return None\n",
    "    x = (b1*c2 - b2*c1)/denom\n",
    "    y = (c1*a2 - c2*a1)/denom\n",
    "    return (x, y)\n",
    "\n",
    "def sort_corners(corners):\n",
    "    \"\"\"\n",
    "    corners: 4 pieces (x,y).\n",
    "\n",
    "    Returns: (top-left, top-right, bottom-right, bottom-left)\n",
    "\n",
    "    The simplest method for:\n",
    "    1) Sort by y axis => top row, bottom row\n",
    "    2) Split top row by x axis => left, right\n",
    "    3) Split bottom row by x axis => left, right\n",
    "    \"\"\"\n",
    "    # 1) All points are in increasing order of y value.\n",
    "    sorted_by_y = sorted(corners, key=lambda p: p[1])\n",
    "    \n",
    "    # 2) First 2 points = top row, last 2 points = bottom row\n",
    "    top_two = sorted_by_y[:2]\n",
    "    bottom_two = sorted_by_y[2:]\n",
    "    \n",
    "    # 3) In the top row, the smaller x value is left, the larger one is right\n",
    "    top_left = min(top_two, key=lambda p: p[0])\n",
    "    top_right = max(top_two, key=lambda p: p[0])\n",
    "    \n",
    "    # 4) In the bottom row, the lower x value is left, the higher one is right\n",
    "    bottom_left = min(bottom_two, key=lambda p: p[0])\n",
    "    bottom_right = max(bottom_two, key=lambda p: p[0])\n",
    "    \n",
    "    return np.array([top_left, top_right, bottom_right, bottom_left], dtype=np.float32)\n",
    "\n",
    "\n",
    "def polygon_area(pts):\n",
    "    \"\"\"\n",
    "    Returns the area of a 2D polygon (shoelace formula).\n",
    "    \"\"\"\n",
    "    area = 0\n",
    "    n = len(pts)\n",
    "    for i in range(n):\n",
    "        j = (i+1)%n\n",
    "        area += pts[i][0]*pts[j][1] - pts[j][0]*pts[i][1]\n",
    "    return abs(area/2)\n",
    "\n",
    "def find_biggest_rectangle(lines_abc, w, h, angle_tol=10):\n",
    "    \"\"\"\n",
    "    From the list of lines (a,b,c) obtained after RANSAC,\n",
    "\n",
    "    it finds the rectangle with the largest area by trying 2 parallel + 2 parallel sets.\n",
    "\n",
    "    - lines_abc: list of (a,b,c)\n",
    "    - w, h: image size\n",
    "    - angle_tol: parallelism angle tolerance (degrees)\n",
    "\n",
    "    Return: corners (4,2) or None\n",
    "    \"\"\"\n",
    "    best_area = 0\n",
    "    best_corners = None\n",
    "    \n",
    "    # Tüm 4'lü kombinasyonları incele\n",
    "    comb4 = combinations(lines_abc, 4)\n",
    "    \n",
    "    for four_lines in comb4:\n",
    "        # 4 çizgi: L0,L1,L2,L3\n",
    "        L0, L1, L2, L3 = four_lines\n",
    "        # Mümkün tüm 2+2 paralel eşleşmeleri\n",
    "        # 6 ikili var: (0,1),(0,2),(0,3),(1,2),(1,3),(2,3)\n",
    "        # Biz 2 disjoint paralel çift arıyoruz\n",
    "        idx_pairs = list(combinations(range(4),2))\n",
    "        \n",
    "        parallel_pairs = []\n",
    "        for (i,j) in idx_pairs:\n",
    "            # paralellik kontrolü\n",
    "            angle_i = line_angle_degrees_abc(*four_lines[i])\n",
    "            angle_j = line_angle_degrees_abc(*four_lines[j])\n",
    "            diff = abs(angle_i - angle_j)\n",
    "            diff = min(diff, 180-diff)\n",
    "            if diff< angle_tol:\n",
    "                parallel_pairs.append((i,j))\n",
    "        \n",
    "        found_set = None\n",
    "        for p1 in parallel_pairs:\n",
    "            for p2 in parallel_pairs:\n",
    "                if len(set(p1).intersection(set(p2)))==0:\n",
    "                    found_set=(p1,p2)\n",
    "                    break\n",
    "            if found_set is not None:\n",
    "                break\n",
    "        \n",
    "        if found_set is None:\n",
    "            continue\n",
    "        \n",
    "        (i1,j1),(i2,j2)= found_set\n",
    "        # Kesişim noktaları: (i1,i2),(i1,j2),(j1,i2),(j1,j2)\n",
    "        p_tl = intersect_abc(four_lines[i1], four_lines[i2])\n",
    "        p_tr = intersect_abc(four_lines[i1], four_lines[j2])\n",
    "        p_bl = intersect_abc(four_lines[j1], four_lines[i2])\n",
    "        p_br = intersect_abc(four_lines[j1], four_lines[j2])\n",
    "        if None in [p_tl,p_tr,p_bl,p_br]:\n",
    "            continue\n",
    "        \n",
    "        corners = np.array([p_tl, p_tr, p_br, p_bl], dtype=np.float32)\n",
    "        # Filtrele image içinde mi\n",
    "        if any((x<0 or x>w or y<0 or y>h) for (x,y) in corners):\n",
    "            continue\n",
    "        \n",
    "        area_val = polygon_area(corners)\n",
    "        if area_val> best_area and area_val>1000:\n",
    "            best_area= area_val\n",
    "            best_corners= corners\n",
    "    \n",
    "    return best_corners\n",
    "\n",
    "def warp_document(original, corners, out_size=(600,800)):\n",
    "    \"\"\"\n",
    "    4 corner (x,y) -> homography -> warp\n",
    "    \"\"\"\n",
    "    if corners is None or len(corners)<4:\n",
    "        return original\n",
    "    sorted_c = sort_corners(corners)\n",
    "    w,h = out_size\n",
    "    dst = np.array([\n",
    "        [0,0],\n",
    "        [w-1,0],\n",
    "        [w-1,h-1],\n",
    "        [0,h-1]\n",
    "    ], dtype=np.float32)\n",
    "    M = cv2.getPerspectiveTransform(sorted_c, dst)\n",
    "    warped = cv2.warpPerspective(original, M, (w,h))\n",
    "    return warped\n",
    "\n",
    "def load_ground_truth(dataset_path, category, file_name):\n",
    "    gt_path = os.path.join(dataset_path, 'digital', category, file_name)\n",
    "    if not os.path.exists(gt_path):\n",
    "        print(\"No ground-truth found:\", gt_path)\n",
    "        return None\n",
    "    gt_img = cv2.imread(gt_path, cv2.IMREAD_COLOR)\n",
    "    return gt_img\n",
    "\n",
    "def compute_ssim(imageA, imageB):\n",
    "    hA, wA = imageA.shape[:2]\n",
    "    hB, wB = imageB.shape[:2]\n",
    "    if (hA!=hB) or (wA!=wB):\n",
    "        imageB = cv2.resize(imageB, (wA,hA), interpolation=cv2.INTER_AREA)\n",
    "    grayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\n",
    "    grayB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n",
    "    score = ssim(grayA, grayB, data_range=grayB.max()-grayB.min())\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Document Processing and SSIM Evaluation\n",
    "\n",
    "This function completes the document dewarping pipeline by performing the following steps:\n",
    "\n",
    "### **Steps:**\n",
    "1. **Loading the Distorted Image**  \n",
    "   - Selects an image from the dataset based on the specified category.\n",
    "   \n",
    "2. **Edge Detection & Hough Transform**  \n",
    "   - Detects edges and applies **Hough Transform** to extract initial line segments.\n",
    "\n",
    "3. **RANSAC-Based Line Refinement**  \n",
    "   - Filters the detected lines using **RANSAC** to improve accuracy.\n",
    "\n",
    "4. **Finding Document Edges and Corners**  \n",
    "   - Identifies the four boundary lines.\n",
    "   - Computes the **intersections (corner points).**\n",
    "   - Applies **perspective transformation** to obtain a frontal view.\n",
    "\n",
    "5. **Loading Ground Truth & SSIM Computation**  \n",
    "   - If a ground-truth image is available, **SSIM** (Structural Similarity Index) is computed to evaluate accuracy.\n",
    "\n",
    "6. **Visualization of Results**  \n",
    "   - Displays the original image, refined RANSAC lines, the warped document, and a side-by-side comparison with the ground truth.\n",
    "\n",
    "### **Challenges & Limitations:**\n",
    "- The method **does not always detect all four document edges correctly,** leading to imperfect warping.\n",
    "- Some **non-document lines are still mistakenly selected**, affecting boundary extraction.\n",
    "- **SSIM evaluation provides a numerical metric**, but it may not fully capture perceptual distortions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_text_lines_roi_ransac_and_warp_with_ssim(dataset_path, category='perspective', file_index=0):\n",
    "    \"\"\"\n",
    "    1) Load distorted image\n",
    "    2) Edge detection + Hough\n",
    "    3) RANSAC refine\n",
    "    4) Find the largest rectangle from all 4-line combinations (find_biggest_rectangle)\n",
    "    5) Warp\n",
    "    6) SSIM\n",
    "    7) Plot\n",
    "    \"\"\"\n",
    "    distorted_folder = os.path.join(dataset_path, 'distorted', category)\n",
    "    files = os.listdir(distorted_folder)\n",
    "    if not files:\n",
    "        print(\"No images in\", distorted_folder)\n",
    "        return\n",
    "    file_name = files[file_index]\n",
    "    distorted_path = os.path.join(distorted_folder, file_name)\n",
    "    \n",
    "    original, edges, doc_mask, masked_edges, lines = detect_lines_for_text_with_mask(\n",
    "        distorted_path,\n",
    "        canny_thresh1=100,\n",
    "        canny_thresh2=200,\n",
    "        pht_threshold=120,\n",
    "        min_line_length=100,\n",
    "        max_line_gap=10\n",
    "    )\n",
    "    if lines is None or len(lines)==0:\n",
    "        print(\"No lines found by Hough.\")\n",
    "        return\n",
    "    \n",
    "    h, w = masked_edges.shape\n",
    "    # RANSAC -> (a,b,c)\n",
    "    refined_lines = fast_ransac_pipeline(lines, masked_edges, w, h)\n",
    "    print(\"Refined lines (a,b,c) count:\", len(refined_lines))\n",
    "    \n",
    "    # Find the largest rectangle\n",
    "    best_corners = find_biggest_rectangle(refined_lines, w, h, angle_tol=10)\n",
    "    if best_corners is None:\n",
    "        print(\"No rectangle found.\")\n",
    "        warped = original\n",
    "    else:\n",
    "        warped = warp_document(original, best_corners, out_size=(600,800))\n",
    "    \n",
    "    # Ground truth\n",
    "    gt_img = load_ground_truth(dataset_path, category, file_name)\n",
    "    if gt_img is None:\n",
    "        print(\"No ground-truth found. Skipping SSIM.\")\n",
    "        ssim_val = None\n",
    "    else:\n",
    "        ssim_val = compute_ssim(warped, gt_img)\n",
    "        print(\"SSIM =\", ssim_val)\n",
    "    \n",
    "    # Plot\n",
    "    lines_img = draw_refined_lines(original, refined_lines)\n",
    "    plt.figure(figsize=(16,6))\n",
    "    \n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Original Distorted\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.imshow(cv2.cvtColor(lines_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Refined RANSAC Lines: {len(refined_lines)}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.imshow(cv2.cvtColor(warped, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Warped Document\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1,4,4)\n",
    "    if gt_img is not None:\n",
    "        gt_resized = cv2.resize(gt_img, (warped.shape[1], warped.shape[0]))\n",
    "        side_by_side = np.hstack((warped, gt_resized))\n",
    "        plt.imshow(cv2.cvtColor(side_by_side, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Compare\\nSSIM={ssim_val:.3f}\" if ssim_val else \"No SSIM\")\n",
    "    else:\n",
    "        plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(\"No GroundTruth\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return ssim_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/Users/demir/Desktop/Assignment1/WarpDoc_resized\"\n",
    "show_text_lines_roi_ransac_and_warp_with_ssim(dataset_path, category='perspective', file_index=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_with_ssim(dataset_path, categories, max_images=50, timeout=30):\n",
    "    \"\"\"\n",
    "    Processes max_images images from each folder (e.g. perspective, curved, fold, incomplete, random, rotate), summing the SSIM value for each image.\n",
    "    Prints the average SSIM after each folder is finished, and presents the results as a table after all folders.\n",
    "    \"\"\"\n",
    "    import signal\n",
    "    # Custom exception for timeout\n",
    "    class TimeoutException(Exception):\n",
    "        pass\n",
    "    def timeout_handler(signum, frame):\n",
    "        raise TimeoutException\n",
    "    signal.signal(signal.SIGALRM, timeout_handler)\n",
    "    \n",
    "    results = {}\n",
    "    for cat in categories:\n",
    "        distorted_folder = os.path.join(dataset_path, 'distorted', cat)\n",
    "        if not os.path.exists(distorted_folder):\n",
    "            print(f\"Folder does not exist: {distorted_folder}\")\n",
    "            continue\n",
    "        files = os.listdir(distorted_folder)\n",
    "        if not files:\n",
    "            print(f\"No images in {distorted_folder}\")\n",
    "            continue\n",
    "        n = min(len(files), max_images)\n",
    "        print(f\"\\nProcessing category: {cat} (up to {n} images)\")\n",
    "        ssim_list = []\n",
    "        for i in range(n):\n",
    "            file_name = files[i]\n",
    "            print(f\"\\n--- {cat} : Image {i+1}/{n} ({file_name}) ---\")\n",
    "            try:\n",
    "                signal.alarm(timeout)\n",
    "                ssim_val = show_text_lines_roi_ransac_and_warp_with_ssim(dataset_path, category=cat, file_index=i)\n",
    "                signal.alarm(0)\n",
    "                if ssim_val is not None:\n",
    "                    ssim_list.append(ssim_val)\n",
    "            except TimeoutException:\n",
    "                print(f\"Image {i+1}/{n} ({file_name}) processing exceeded {timeout} seconds. Skipping.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {i+1}/{n} ({file_name}): {e}\")\n",
    "                signal.alarm(0)\n",
    "        if ssim_list:\n",
    "            avg_ssim = sum(ssim_list)/len(ssim_list)\n",
    "            print(f\"Category '{cat}': Average SSIM = {avg_ssim:.3f}\")\n",
    "            results[cat] = avg_ssim\n",
    "        else:\n",
    "            print(f\"Category '{cat}': No SSIM computed.\")\n",
    "            results[cat] = None\n",
    "\n",
    "    # Creating tables for all categories\n",
    "    print(\"\\nFinal SSIM Results:\")\n",
    "    print(\"{:<15} {:<10}\".format(\"Category\", \"Avg SSIM\"))\n",
    "    print(\"-\"*25)\n",
    "    for cat in categories:\n",
    "        avg = results.get(cat, None)\n",
    "        if avg is not None:\n",
    "            print(\"{:<15} {:<10.3f}\".format(cat, avg))\n",
    "        else:\n",
    "            print(\"{:<15} {:<10}\".format(cat, \"N/A\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/Users/demir/Desktop/Assignment1/WarpDoc_resized\"\n",
    "categories = [\"perspective\", \"curved\", \"fold\", \"incomplete\", \"random\", \"rotate\"]\n",
    "process_images_with_ssim(dataset_path, categories, max_images=50, timeout=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
